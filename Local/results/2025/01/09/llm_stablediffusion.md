---
title: "Stable Diffusion Subreddit"
date: "2025-01-09"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["AI", "Machine Learning", "Image Generation"]
---

# Overall Ranking and Top Discussions
1.  [[D] TransPixar: a new generative model that preserves transparency,](https://v.redd.it/cptyirqkbvbe1) (Score: 2065)
    *  Users are excited about the potential of this new generative model, particularly its ability to preserve transparency for VFX artists.
2.  [Hunyuan Video is really an amazing gift to the open-source community.](https://v.redd.it/4zywqwwwwzbe1) (Score: 405)
    *   The community is discussing the impressive capabilities of Hunyuan Video, particularly its speed and quality for local AI video generation, but also the lack of an img2vid model and its non-open source license.
3. [Specify age for Flux](https://v.redd.it/cmnappilosbe1) (Score: 388)
    *  Users are exploring methods to accurately specify the age of people in images generated with Flux, and discussing issues with certain age generations.
4.  [Pixel Art Character Sheets (Prompts Included)](https://www.reddit.com/gallery/1hxjbld) (Score: 126)
     * Users are sharing pixel art character sheets generated by AI, inquiring about the models used, and discussing how to address inconsistencies.
5.  [Improve Hunyuan's speed by 1.75x with minimal quality loss with "First Block Cache".](https://www.reddit.com/r/StableDiffusion/comments/1hx28u5/improve_hunyuans_speed_by_175x_with_minimal/) (Score: 121)
    *  The community is testing and discussing a new method to improve the speed of Hunyuan, and comparing it to other methods like TeaCache.
6.  [Has Kijai Ever Slept? Serious Question.](https://www.reddit.com/r/StableDiffusion/comments/1hxg8p7/has_kijai_ever_slept_serious_question/) (Score: 118)
     * Users are praising Kijai for the amount of work he's contributed to the community, while also joking about his work ethic, and being curious about his background.
7.  [nVidia SANA 4k (4096x4096) has been released](https://huggingface.co/Efficient-Large-Model/Sana_1600M_4Kpx_BF16) (Score: 95)
    *  The community discusses the release of nVidia SANA 4k, its capabilities, and limitations, and tries to get it to run with ComfyUI.
8.  [Anyone want the script to run Moondream 2b's new gaze detection on any video?](https://v.redd.it/t50q2ta681ce1) (Score: 72)
     * Users are showing interest in a script for Moondream 2b's gaze detection, but are asking for tutorials/workflows for better understanding it and implementing it.
9.  [Sticky negatives: how to get a broad performance uplift on all models. All images were generated at 30 cfg at arbitrary high res, without any post-processing, on video. Link in comments.](https://www.reddit.com/gallery/1hx8wun) (Score: 64)
    *  The community is analyzing the effectiveness of "sticky negatives", sharing their experiments, and theorizing how they work in SD.
10.  [New form stability, SPAR3D: Stable Point-Aware Reconstruction of 3D Objects from Single Images](https://www.reddit.com/r/StableDiffusion/comments/1hx4tli/new_form_stability_spar3d_stable_pointaware/) (Score: 50)
     * Users are discussing a new 3D reconstruction model, SPAR3D, comparing it to a similar model called Trellis, and suggesting improvements.
11.  [SDXL GGUF models and Clip Encoders uploaded at Hugging Face](https://www.reddit.com/r/StableDiffusion/comments/1hx7y5t/sdxl_gguf_models_and_clip_encoders_uploaded_at/) (Score: 40)
     * Users are showing interest in the uploaded GGUF models and clip encoders, and asking for further conversions and support for other models.
12.  [Hunyuan Lora train- consistent character ](https://v.redd.it/1qgzj1abj0ce1) (Score: 38)
      * Users are sharing their Lora training experiences on Hunyuan video model, discussing training costs, and asking about the prompts used and training dataset.
13. [ComfyUI-TangoFlux:- ComfyUI Custom Nodes for "TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching"](https://github.com/LucipherDev/ComfyUI-TangoFlux) (Score: 11)
    * Users are sharing links to the paper and demo page for TangoFlux.
14.  [Tried Cloth Swapping With Flux Fill and Redux.](https://i.redd.it/ipm29jdkt0ce1.png) (Score: 7)
    *  Users are sharing workflows and links to videos for cloth swapping using Flux Fill and Redux
15. [Monthly Showcase Thread - January 2024](https://www.reddit.com/r/StableDiffusion/comments/1hx3rv2/monthly_showcase_thread_january_2024/) (Score: 6)
     * Users are showcasing their AI generated artwork in the monthly showcase thread.
16.  [Any experience with the Intel Arc? ](https://www.reddit.com/r/StableDiffusion/comments/1hxf4b1/any_experience_with_the_intel_arc/) (Score: 5)
    *  The community discusses the performance and issues of Intel Arc GPUs when used for Stable Diffusion, particularly regarding generation time overhead.
17.  [SD3.5 and LORAs [artifacts and quantization]](https://www.reddit.com/r/StableDiffusion/comments/1hxi9sw/sd35_and_loras_artifacts_and_quantization/) (Score: 5)
     * Users are discussing potential causes and solutions for artifacts arising when training Lora models in SD 3.5.
18. [Monthly Promotion Thread - January 2024](https://www.reddit.com/r/StableDiffusion/comments/1hx3qj1/monthly_promotion_thread_january_2024/) (Score: 4)
     * Users are sharing links to their work and projects in the monthly promotion thread.
19.   [Any AI art communities for more advanced SD users?](https://www.reddit.com/r/StableDiffusion/comments/1hxof0n/any_ai_art_communities_for_more_advanced_sd_users/) (Score: 4)
     * Users are looking for AI art communities for more advanced SD users, and also mentioning Discord as a viable option.

# Detailed Analysis by Thread
**[TransPixar: a new generative model that preserves transparency, (Score: 2065)](https://v.redd.it/cptyirqkbvbe1)**
*  **Summary:**  This thread is centered around the introduction of TransPixar, a new generative model capable of preserving transparency. The discussion includes excitement about its potential impact on the VFX industry, its usefulness for generating overlay effects, and questions about its licensing. There are also concerns about how AI advancements may impact jobs in the VFX field.
*  **Emotion:** The overall emotional tone is positive, marked by excitement and optimism about the capabilities of the new model. However, there is a hint of concern regarding job displacement within the VFX industry.
*  **Top 3 Points of View:**
    *   TransPixar is a significant advancement in generative models, especially for VFX.
    *   The model will be disruptive and useful for generating transparency.
    *   Some are concerned about the impact on the job market, and the open source status.

**[Hunyuan Video is really an amazing gift to the open-source community. (Score: 405)](https://v.redd.it/4zywqwwwwzbe1)**
*  **Summary:** This thread discusses the Hunyuan Video model, highlighting its impressive features as an open-source offering. Users express admiration for its video generation capabilities, ease of training, and uncensored nature. However, some note the lack of an img2vid model and point out that the Tencent Community License is not truly open source.
*  **Emotion:** The emotional tone is predominantly positive, with users expressing excitement and appreciation for the Hunyuan model. There are also some negative sentiments, however, due to licensing and some feature limitations.
*  **Top 3 Points of View:**
    *   Hunyuan is an amazing step up from other local AI video models and is easy to use.
    *   The absence of an image-to-video model is a significant drawback.
    *   The license is restrictive and does not meet the standards of open-source.

**[Specify age for Flux (Score: 388)](https://v.redd.it/cmnappilosbe1)**
*  **Summary:** Users are discussing how to accurately specify the age of people in images generated using Flux, particularly focusing on the effectiveness of the "yo" (years old) format. The thread highlights issues with generating very young or very old people, and biases within the model regarding age representation. Some people are discussing their own experiences with age representation and how it should work, some are suggesting better ways to handle it.
*  **Emotion:** The thread's emotional tone is mostly neutral, with a mix of curiosity and analytical thinking as users explore the functionality of Flux. There's also slight disappointment that certain age generations aren't working as expected.
*  **Top 3 Points of View:**
    *   The "yo" format is generally a good way to specify age in Flux, but there are issues with certain ages.
    *   The model may have biases in how it represents certain age groups.
    *  It is better to use the terms "mid" or "late" in conjunction with a decade than to use exact years, and reduce the guidance values to improve the photorealism.

**[Pixel Art Character Sheets (Prompts Included) (Score: 126)](https://www.reddit.com/gallery/1hxjbld)**
*  **Summary:**  This thread features a discussion around pixel art character sheets generated using AI, where the poster includes the prompts used.  Users praise the work, but also point out inconsistencies in the pixel sizes and between different views. Some users also ask for more details about the model, and want to use the prompts provided to recreate the result.
*  **Emotion:** The overall emotional tone is positive, with users showing enthusiasm for the work and eagerness to learn more about how to create similar results.
*  **Top 3 Points of View:**
    *   The pixel art character sheets are impressive.
    *   There is a desire for greater consistency between different character views.
    *  Users are asking for more information about the model used, prompts, and workflow for this work.

**[Improve Hunyuan's speed by 1.75x with minimal quality loss with "First Block Cache". (Score: 121)](https://www.reddit.com/r/StableDiffusion/comments/1hx28u5/improve_hunyuans_speed_by_175x_with_minimal/)**
*  **Summary:** This thread focuses on a method of using "First Block Cache" to improve the speed of Hunyuan video generation. Users are sharing their experiences trying this new method, discussing issues of compatibility with other models and features like TeaCache, and asking for the workflow used.
*  **Emotion:** The emotional tone is mixed, with some users reporting success, while others faced issues with the method. There's a general curiosity to learn more.
*  **Top 3 Points of View:**
    *   First Block Cache can potentially improve Hunyuan's generation speed.
    *   The method is not universally compatible and can be difficult to implement.
    *  Users want more information about the workflow and how it compares to other speedup methods.

**[Has Kijai Ever Slept? Serious Question. (Score: 118)](https://www.reddit.com/r/StableDiffusion/comments/1hxg8p7/has_kijai_ever_slept_serious_question/)**
*  **Summary:** This thread is dedicated to praising Kijai, a prolific contributor to the stable diffusion community. Users express admiration for Kijai's work ethic and number of different contributions to the community, and are curious about who he is. Kijai himself shares that he has had sleep issues in the past year and that he's a product of AI assistance.
*  **Emotion:** The overall tone is positive and admiring, with elements of humor and curiosity as the community expresses gratitude and interest in Kijai.
*  **Top 3 Points of View:**
    *   Kijai is a highly respected and hardworking contributor to the community.
    *   He has made many contributions using AI assistance.
    *   Users are curious about his background and work.

**[nVidia SANA 4k (4096x4096) has been released (Score: 95)](https://huggingface.co/Efficient-Large-Model/Sana_1600M_4Kpx_BF16)**
*  **Summary:** This thread is about the release of nVidia SANA 4k, with a focus on its capabilities, limitations, and usage. Users discuss the model's performance, its license, which is non-commercial, and the challenges of getting it to work in ComfyUI. Some also explore its ability to work on lower spec systems or train with it, as well as mentioning issues in its encoding and decoding of images.
*  **Emotion:** The emotional tone is neutral to positive. Some people are excited about its potential but also frustrated with its limitations and licensing.
*  **Top 3 Points of View:**
    *   SANA 4k is a potentially powerful model but has some issues.
    *  Its non-commercial license is restrictive.
    *  Getting it to work in ComfyUI is proving to be difficult.

**[Anyone want the script to run Moondream 2b's new gaze detection on any video? (Score: 72)](https://v.redd.it/t50q2ta681ce1)**
*  **Summary:**  The thread revolves around a user offering a script for running Moondream 2b's gaze detection.  Users are expressing interest but also ask for a tutorial/workflow for better understanding and implementation, and discuss how it could be useful for video games, and AI agents. Some users also mention current shortcomings with inpainting and suggest using this model to train controlnets.
*  **Emotion:**  The general emotional tone is positive and curious, with users expressing interest in learning and experimenting with the new technology.
*  **Top 3 Points of View:**
    *   Users are interested in trying out the gaze detection script.
    *   The community is asking for more guidance on how to implement this tool
    *  This technology could be useful for various purposes.

**[Sticky negatives: how to get a broad performance uplift on all models. All images were generated at 30 cfg at arbitrary high res, without any post-processing, on video. Link in comments. (Score: 64)](https://www.reddit.com/gallery/1hx8wun)**
*  **Summary:** This thread is a deep dive into a "sticky negatives" technique, where the user includes the positive prompt into the negative prompt. Users are testing this method in ComfyUI and sharing their results. They discuss how it may reduce prompt adherence, and theorize how it works in conjunction with CFG, and suggest further experiments.
*  **Emotion:** The emotional tone is mixed. Users are curious, but skeptical, as they are testing it and trying to understand the underlying mechanism behind this technique.
*  **Top 3 Points of View:**
    *   Sticky negatives can produce different results but not necessarily better.
    *  Some newer models perform well without negative prompts, questioning the necessity of this technique
    *  There are theories as to how the method works, and it is worth experimenting further.

**[New form stability, SPAR3D: Stable Point-Aware Reconstruction of 3D Objects from Single Images (Score: 50)](https://www.reddit.com/r/StableDiffusion/comments/1hx4tli/new_form_stability_spar3d_stable_pointaware/)**
*  **Summary:** This thread discusses the capabilities of SPAR3D, a new tool for reconstructing 3D objects from single images.  Users compare its performance to Trellis, a similar model, and express concerns over quality and speed. They discuss the potential of including multiple images as input for more detailed 3D models.
*  **Emotion:** The general emotion is neutral to slightly negative, with some users expressing disappointment with the quality of SPAR3D compared to existing alternatives.
*   **Top 3 Points of View:**
    *   SPAR3D's performance isn't great compared to other similar models, like Trellis.
    *  Users suggest that the developers should focus on quality instead of speed
    *   Including multiple images as input could significantly improve the detail of the 3D reconstruction.

**[SDXL GGUF models and Clip Encoders uploaded at Hugging Face (Score: 40)](https://www.reddit.com/r/StableDiffusion/comments/1hx7y5t/sdxl_gguf_models_and_clip_encoders_uploaded_at/)**
*   **Summary:** This thread is focused on newly uploaded SDXL GGUF models and Clip Encoders on Hugging Face, with users asking questions about the models. People want to know more about the quality hit, the installation process, the differences with other models such as Flux GGUF's, and if they work with LoRAs. Users are also requesting additional models to be converted to GGUF format.
*  **Emotion:** The tone is generally positive, with a focus on inquiry and gratitude for the effort of the uploader.
*  **Top 3 Points of View:**
    *   Users are interested in using the new GGUF models.
    *   They want to know more about the technical aspects, such as the quality of the generated images, the installation process and compatibility with Loras.
    *  They would like more models and features to be converted to GGUF format.

**[Hunyuan Lora train- consistent character  (Score: 38)](https://v.redd.it/1qgzj1abj0ce1)**
*  **Summary:** The thread is about training a Lora model with the Hunyuan video model to create a consistent character. The poster talks about his training process and how it took 15 hours on a A100 GPU and the result was generated inside ComfyUI. Users ask about the prompts used and the costs associated with training on A100 GPUs, as well as what type of dataset is required for a video lora.
*   **Emotion:** The overall emotion is positive with the community showing enthusiasm for the Lora creation with the Hunyuan video model.
*   **Top 3 Points of View:**
    *   Training a Lora on Hunyuan for consistent character generation is feasible.
    *   Training costs on an A100 GPU can be high.
    *  There is a desire to learn more about the training process and prompts.

**[ComfyUI-TangoFlux:- ComfyUI Custom Nodes for "TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching" (Score: 11)](https://github.com/LucipherDev/ComfyUI-TangoFlux)**
*   **Summary:** This thread is centered around the sharing of a ComfyUI custom node for "TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching," and the associated research paper and demo page.
*   **Emotion:** The emotional tone is purely informative.
*   **Top 3 Points of View:**
    *  TangoFlux is a new text to audio generation model.
    *  It is described as "Super Fast and Faithful."
    * ComfyUI nodes for it have been released

**[Tried Cloth Swapping With Flux Fill and Redux. (Score: 7)](https://i.redd.it/ipm29jdkt0ce1.png)**
*   **Summary:** This thread is simply showcasing a workflow for cloth swapping with Flux Fill and Redux, and includes links to the workflow in pastebin and a YouTube tutorial.
*   **Emotion:** The emotional tone is purely informative.
*   **Top 3 Points of View:**
    * The poster has shared a workflow for cloth swapping with Flux Fill and Redux.
    * The workflow is based on a Youtube tutorial.
    * The workflow is available via pastebin.

**[Monthly Showcase Thread - January 2024 (Score: 6)](https://www.reddit.com/r/StableDiffusion/comments/1hx3rv2/monthly_showcase_thread_january_2024/)**
*   **Summary:** This is a monthly thread where users share their AI generated images and projects, the content is very varied.
*   **Emotion:** The emotional tone is mixed, with users showing off their work with mostly positive feedback.
*  **Top 3 Points of View:**
    *   Users are showcasing various AI-generated art.
    *   Some users are sharing projects that involve using AI generated images for books and Loras.
    *   Users are sharing varied image outputs, including character portraits, fantasy art, and more.

**[Any experience with the Intel Arc?  (Score: 5)](https://www.reddit.com/r/StableDiffusion/comments/1hxf4b1/any_experience_with_the_intel_arc/)**
*  **Summary:** This thread discusses user experiences with Intel Arc GPUs for Stable Diffusion. The main focus is on performance issues, including inconsistent results, longer than expected generation times, and additional overhead. The community speculates on what could be causing these issues.
*  **Emotion:** The overall tone is neutral to somewhat frustrated, with users trying to diagnose the performance issues of the Arc GPUs.
*  **Top 3 Points of View:**
    *   Intel Arc GPUs can be used for Stable Diffusion, but performance is inconsistent.
    *   There's a significant overhead, resulting in longer generation times.
    *   PyTorch's asynchronous behavior may contribute to these inconsistencies.

**[SD3.5 and LORAs [artifacts and quantization] (Score: 5)](https://www.reddit.com/r/StableDiffusion/comments/1hxi9sw/sd35_and_loras_artifacts_and_quantization/)**
*   **Summary:** This thread is dedicated to discussing potential causes and solutions for issues related to artifacts and quantization when training Lora models with SD 3.5.  The focus is on explaining how different factors can affect the quality, like the text sequence lenght, the type of model used, and the need for extra DiT layers.
*   **Emotion:** The overall tone is neutral, with a focus on technical analysis and problem-solving.
*   **Top 3 Points of View:**
    *   The text sequence length for SD 3.5 Lora training should be 154.
    *  Quantizing a parameter-starved model may lead to visible issues.
    *  MMDiT models need extra DiT layers for stable Lora training.

**[Monthly Promotion Thread - January 2024 (Score: 4)](https://www.reddit.com/r/StableDiffusion/comments/1hx3qj1/monthly_promotion_thread_january_2024/)**
*  **Summary:**  This is a monthly promotion thread for users to share their work and projects, which includes a public domain book algorithmically illustrated and a link to a free image generation mobile app.
*  **Emotion:** The overall tone is informative and promotional.
*  **Top 3 Points of View:**
    *   Users are sharing a book illustrated with AI-generated art.
    *   There is a free image-generation app being promoted
    * This thread is a place for people to share their projects.

**[Any AI art communities for more advanced SD users? (Score: 4)](https://www.reddit.com/r/StableDiffusion/comments/1hxof0n/any_ai_art_communities_for_more_advanced_sd_users/)**
*   **Summary:** The thread is a discussion about finding art communities for advanced Stable Diffusion users. Users are talking about the difficulty of finding such a community, and also suggesting alternative solutions such as discord channels and getting feedback from non-AI specific communities.
*  **Emotion:** The overall tone is a mix of frustration and hope, as users search for better places to discuss AI art.
*   **Top 3 Points of View:**
    *   It is difficult to find AI art communities for advanced users.
    *   Discord channels offer some good alternatives.
    *   Seeking feedback from non-AI specific communities is recommended.
