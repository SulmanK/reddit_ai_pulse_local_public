---
title: "Machine Learning Subreddit"
date: "2025-01-09"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machine learning", "AI", "LLMs"]
---

# Overall Ranking and Top Discussions
1.  [[D] Why does training LLMs *** so much?](https://www.reddit.com/r/MachineLearning/comments/1hx6q8r/d_why_does_training_llms_suck_so_much/) (Score: 95)
    * The discussion revolves around the difficulties and resource demands of training large language models (LLMs).
2.  [[D] ML Engineers, what's the most annoying part of your job?](https://www.reddit.com/r/MachineLearning/comments/1hwbhuj/d_ml_engineers_whats_the_most_annoying_part_of/) (Score: 81)
    * ML engineers share the most frustrating aspects of their roles, including dealing with management, data issues, and inconsistent expectations.
3.  [[R][N] TabPFN v2: Accurate predictions on small data with a tabular foundation model](https://www.reddit.com/r/MachineLearning/comments/1hwvk9x/rn_tabpfn_v2_accurate_predictions_on_small_data/) (Score: 49)
    * Users discuss the TabPFN v2 model, focusing on its capabilities with small datasets and how it compares to existing methods.
4.  [[D] To Fellow researchers: What are your top 3 challenges in research?](https://www.reddit.com/r/MachineLearning/comments/1hwh8um/d_to_fellow_researchers_what_are_your_top_3/) (Score: 39)
    * Researchers discuss common obstacles such as reproducibility issues, access to computing resources, and defining relevant problem statements.
5.  [[R] rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking](https://arxiv.org/abs/2501.04519) (Score: 37)
    * The conversation centers on a research paper about small LLMs and their ability to perform math reasoning with a self-evolved deep thinking approach.
6.  [[D] Monthly Who's Hiring and Who wants to be Hired?](https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/) (Score: 34)
    * This thread lists various job postings and individuals seeking employment in the field of AI and data science.
7.  [[D] [R] First PhD paper decision: IJCAI or ICML](https://www.reddit.com/r/MachineLearning/comments/1hx4o3z/d_r_first_phd_paper_decision_ijcai_or_icml/) (Score: 27)
     * Users discuss whether to submit their first PhD paper to IJCAI or ICML, including their differences.
8.  [[R] ObliqueTree: Advanced Decision Tree Implementation](https://www.reddit.com/r/MachineLearning/comments/1hxa6u6/r_obliquetree_advanced_decision_tree/) (Score: 23)
    *  This thread discusses an advanced decision tree implementation called ObliqueTree, its features, and its potential benefits.
9.  [[D] Self-Promotion Thread](https://www.reddit.com/r/MachineLearning/comments/1htw7hw/d_selfpromotion_thread/) (Score: 10)
    *  Various users share their latest projects, research papers, tools, and job opportunities.
10. [[R] Dynamic Time Warping on animal vocalizations](https://www.reddit.com/r/MachineLearning/comments/1hx88ip/r_dynamic_time_warping_on_animal_vocalizations/) (Score: 6)
     * This thread discusses the application of Dynamic Time Warping (DTW) on animal vocalizations, and if the implementation makes sense for the specific data.
11. [[R] Seminar on Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues](https://www.reddit.com/r/MachineLearning/comments/1hxgovs/r_seminar_on_unlocking_statetracking_in_linear/) (Score: 5)
    *  A seminar regarding research on Linear Recurrent Neural Networks (LRNNs) and their state-tracking abilities through the use of negative eigenvalues.
12.  [[P] Facing Hardware Limits - How to go ahead?](https://www.reddit.com/r/MachineLearning/comments/1hxnqkw/p_facing_hardware_limits_how_to_go_ahead/) (Score: 1)
     * The thread touches on overcoming hardware limitations in machine learning projects.
13. [looking for an 18+ dataset to train my ai [Project]](https://www.reddit.com/r/MachineLearning/comments/1hxnvgs/looking_for_an_18_dataset_to_train_my_ai_project/) (Score: 0)
     * Users discuss about the availability of 18+ data for training models.
14. [[D] [R] [P] Building a *** Recognition System for Attendance](https://www.reddit.com/r/MachineLearning/comments/1hxdjy5/d_r_p_building_a_facial_recognition_system_for/) (Score: 0)
    *  This is a discussion about developing a facial recognition system for attendance, including implementation and ethical concerns.
15.  [[P] Fish illness object detection and identification](https://www.reddit.com/r/MachineLearning/comments/1hxmrk2/p_fish_illness_object_detection_and_identification/) (Score: 0)
     * A thread about the use of object detection and identification for fish illness detection.

# Detailed Analysis by Thread
**[ [D] Why does training LLMs *** so much? (Score: 95)](https://www.reddit.com/r/MachineLearning/comments/1hx6q8r/d_why_does_training_llms_suck_so_much/)**
*  **Summary:** This thread explores the reasons behind the difficulty and resource intensiveness of training large language models (LLMs). Users discuss the computational demands, the need for massive datasets, and the complexity of the underlying models.
*  **Emotion:** The overall emotional tone is neutral. The discussion is informative, with users sharing their insights and experiences related to LLM training.
*  **Top 3 Points of View:**
    *   LLMs are essentially highly compressed N-gram models, and their large parameter size necessitates significant training resources.
    *   Building smaller models to get basic convergence working is a good approach before tackling larger models.
    *   The commercial value of high-performing LLMs drives the need to push the boundaries of compute, incentivizing pushing the limits of resources.

**[ [D] ML Engineers, what's the most annoying part of your job? (Score: 81)](https://www.reddit.com/r/MachineLearning/comments/1hwbhuj/d_ml_engineers_whats_the_most_annoying_part_of/)**
*  **Summary:** ML engineers share their frustrations, including management's lack of understanding of ML processes, issues with data quality, difficulties with project scoping, and mismatched expectations between stakeholders.
*  **Emotion:** The general emotional tone of the thread is negative, with users expressing annoyance and frustration.
*  **Top 3 Points of View:**
    *   Upper management often tries to apply software development processes to ML projects, which don't work well.
    *   Data quality issues, including the lack of proper inspection and handling of datasets, are a major source of frustration.
    *   Inconsistent stakeholder views and loose requirements lead to project inefficiencies and wasted time.

**[ [R][N] TabPFN v2: Accurate predictions on small data with a tabular foundation model (Score: 49)](https://www.reddit.com/r/MachineLearning/comments/1hwvk9x/rn_tabpfn_v2_accurate_predictions_on_small_data/)**
*  **Summary:** This discussion focuses on the TabPFN v2 model, highlighting its ability to make accurate predictions on small datasets. Users discuss its potential, limitations, and comparisons to other methods.
*  **Emotion:** The emotional tone is generally positive, with some users expressing excitement about the model's potential, and others remaining skeptical.
*  **Top 3 Points of View:**
    *   Some users are excited to try TabPFN v2 on their company's data, viewing it as a promising tool.
    *   Others remain skeptical and require to see it winning competitions like kaggle to prove its worth.
    *   Users are interested in how TabPFN v2 compares to other tabular models like TabM and GANDALF, as well as conventional methods like XGBoost.

**[ [D] To Fellow researchers: What are your top 3 challenges in research? (Score: 39)](https://www.reddit.com/r/MachineLearning/comments/1hwh8um/d_to_fellow_researchers_what_are_your_top_3/)**
*  **Summary:**  Researchers in the field of Machine Learning discuss their top challenges, such as lack of reproducible code/data, the difficulties of finding a relevant research problem, and insufficient computing resources.
*  **Emotion:** The overall tone is neutral, as users primarily discuss challenges. Some comments express frustration or negative sentiment.
*  **Top 3 Points of View:**
    *   The inability to reproduce results due to unavailable code or training splits is a major problem in the research.
    *   Defining and narrowing down a research problem statement, especially for newer researchers, is very difficult.
    *   Lack of sufficient compute resources acts as a significant bottleneck, especially in the age of large models.

**[ [R] rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking (Score: 37)](https://arxiv.org/abs/2501.04519)**
*  **Summary:** This thread analyzes a research paper about small LLMs mastering math reasoning, with discussion about the cost of the methodology, the complexity of the baselines, and the implications of the research.
*  **Emotion:** The emotional tone is neutral, focusing on technical analysis and discussion, with some expressing skepticism.
*   **Top 3 Points of View:**
    *   The cost of finetuning models, even smaller ones, is substantial and this is not a simple baseline.
    *  The research raises questions about if OpenAI might be using smaller models and that smaller models may actually be better at some reasoning problems.
    *   The performance gains come from the PPM (Policy Planning Module), and learning good CoT (Chain-of-Thought) strategies with RL is not simple.

**[ [D] Monthly Who's Hiring and Who wants to be Hired? (Score: 34)](https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/)**
*   **Summary:** This is a monthly thread where individuals and companies can post available job positions and those looking for work. It serves as a hub for connecting people in the Machine Learning field.
*   **Emotion:** The thread is mostly neutral, as it's a functional listing of job-related information, some users do display a positive sentiment.
*   **Top 3 Points of View:**
    *   Companies are looking for Data Scientists/ML Engineers with strong PyTorch and Graph Neural Networks expertise, among other requirements.
    *   Professionals are seeking remote or hybrid roles with salary expectations within specific ranges, with a background in data science, and machine learning.
    *   Faculty members are looking for PhD students in areas such as Causality and ML.

**[ [D] [R] First PhD paper decision: IJCAI or ICML (Score: 27)](https://www.reddit.com/r/MachineLearning/comments/1hx4o3z/d_r_first_phd_paper_decision_ijcai_or_icml/)**
*  **Summary:** The discussion revolves around choosing between IJCAI and ICML for a first PhD paper submission, with users debating the prestige, suitability based on topic, and practical considerations.
*  **Emotion:** The overall tone is neutral and somewhat positive as users provide advice and support.
*  **Top 3 Points of View:**
    *   ICML is generally considered a more prestigious and impactful venue than IJCAI, especially for GenAI, LLMs and RL, but for symbolic AI or game theory, IJCAI may be more suitable.
    *   If you are early in your PhD, submitting to ICML first is recommended due to its higher payoff; IJCAI is more suitable if getting published is the priority.
    *   Some users question how 'top' venues are defined. They also suggest that the acceptance rate is not a good measure of a venue's impact and that it is more important to address reviewers' comments.

**[ [R] ObliqueTree: Advanced Decision Tree Implementation (Score: 23)](https://www.reddit.com/r/MachineLearning/comments/1hxa6u6/r_obliquetree_advanced_decision_tree/)**
*   **Summary:** The thread is about ObliqueTree, an advanced decision tree implementation. It discusses its ability to split space with linear projections, its performance on synthetic data, and its features, including categorical feature handling.
*   **Emotion:** The overall tone is neutral with some positive comments, as users discuss technical aspects and potential improvements.
*   **Top 3 Points of View:**
    *   Oblique trees are capable of handling synthetic data and provide a good alternative to classical linear tree approaches.
    *   The ability to handle categorical features natively is important, because the implementation of it in existing implementations is often not optimal.
    *   Citing prior work is important to give due credit and the author should focus on this in the future.

**[ [D] Self-Promotion Thread (Score: 10)](https://www.reddit.com/r/MachineLearning/comments/1htw7hw/d_selfpromotion_thread/)**
*   **Summary:** This is a self-promotion thread where users share their research papers, tools, job opportunities, and personal projects related to machine learning.
*   **Emotion:** The overall tone is positive, with users excited to share their work and accomplishments.
*   **Top 3 Points of View:**
    *   Researchers are sharing new papers focusing on Dense Reward RLHF for Language Models, and Cross-Layer Cache Aggregation for token reduction.
    *   Users are developing and promoting tools like curated listing platforms for AI agents and AI platforms.
    *   Individuals are showcasing practical applications of machine learning, like gaze detection and the creation of synthetic data.

**[ [R] Dynamic Time Warping on animal vocalizations (Score: 6)](https://www.reddit.com/r/MachineLearning/comments/1hx88ip/r_dynamic_time_warping_on_animal_vocalizations/)**
*  **Summary:** Users discuss the implementation of Dynamic Time Warping (DTW) on animal vocalizations and the challenges with using it directly on raw spectrograms. They suggest alternative approaches such as using MFCCs, alternative distance measures, or identifying peak frequencies.
*  **Emotion:** The overall tone is somewhat negative, reflecting the challenges of applying DTW directly to the given data.
*  **Top 3 Points of View:**
    *   DTW does not perform well on high dimensional data and a lower dimensionality approach like MFCC is preferred.
    *   The current raw spectrograms have a lot of noise and very little signal, so other distance metrics are preferred.
     * Transforming the data to peak frequencies and using methods like Hidden Markov Models might be more effective.

**[ [R] Seminar on Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1hxgovs/r_seminar_on_unlocking_statetracking_in_linear/)**
*  **Summary:** This thread announces a seminar discussing how Linear Recurrent Neural Networks (LRNNs) can improve their state-tracking by incorporating negative eigenvalues, challenging traditional assumptions about the limitations of LRNNs.
*  **Emotion:** The emotional tone is neutral, as it is mainly informational.
*   **Top 3 Points of View:**
    *   LRNNs can improve their state-tracking capabilities by incorporating negative eigenvalues.
    *   The research shows that this allows LRNNs to handle complex tasks like maintaining multiple state patterns and recognizing sequences more effectively.
    *   This insight challenges conventional understanding that eigenvalues must be positive.

**[ [P] Facing Hardware Limits - How to go ahead? (Score: 1)](https://www.reddit.com/r/MachineLearning/comments/1hxnqkw/p_facing_hardware_limits_how_to_go_ahead/)**
*   **Summary:** This thread discusses strategies to overcome hardware limitations in machine learning, specifically highlighting improving token efficiency and mixed precision operations.
*   **Emotion:** The sentiment is positive, as the discussion focuses on solutions.
*   **Top 3 Points of View:**
    *   There is research on improving token efficiency to overcome hardware limitations.
    *   Mixed precision operations can be used to reduce resource demands.

**[ looking for an 18+ dataset to train my ai [Project] (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1hxnvgs/looking_for_an_18_dataset_to_train_my_ai_project/)**
*   **Summary:** This thread is about a user looking for a specific type of 18+ dataset to train an AI project, with others offering suggestions ranging from kama-sutra datasets to web-scraping.
*   **Emotion:** The overall tone is neutral.
*   **Top 3 Points of View:**
    *   The user is having trouble finding a publicly available dataset for training.
    *   Some users suggest using kama-sutra data and deep danbooru.
     * Others suggest web-scraping the data.

**[ [D] [R] [P] Building a *** Recognition System for Attendance (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1hxdjy5/d_r_p_building_a_facial_recognition_system_for/)**
*   **Summary:** This discussion centers on building a facial recognition system for attendance tracking, including considerations of deployment, technology, and ethics.
*   **Emotion:** The tone is mixed, with some neutral comments regarding technology implementation and some more negative comments related to the topic.
*   **Top 3 Points of View:**
    *   The system should be implemented as a web application for easy deployment across operating systems.
    *   There are existing tensorflow.js face embedding models that could be used, or deepstack or compressive could be an alternative if not in the browser.
    *   There are ethical concerns with the use of facial recognition for attendance tracking that should be considered.

**[ [P] Fish illness object detection and identification (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1hxmrk2/p_fish_illness_object_detection_and_identification/)**
*   **Summary:** This thread asks for advice and guidance related to an object detection and identification system for fish illnesses.
*   **Emotion:** The overall tone is neutral and positive, with users offering suggestions and help.
*   **Top 3 Points of View:**
    *   There are subreddits for beginner questions like r/mlquestions and r/learnmachinelearning.
    *   Users suggest treating the problem as an LLM problem instead of a custom machine learning problem.
